{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb9870e2",
   "metadata": {},
   "source": [
    "### Text Mining Assignment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcbda4e",
   "metadata": {},
   "source": [
    "#### 2nd Problem Statement\n",
    "\n",
    "Extract reviews of any product from ecommerce website like amazon & Perform emotion mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d254197",
   "metadata": {},
   "source": [
    "### Web Scarping Amazon Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "230dfc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  #--to ignore warnings\n",
    "\n",
    "HEADERS = ({'User-Agent':\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "            AppleWebKit/537.36 (KHTML, like Gecko) \\\n",
    "            Chrome/90.0.4430.212 Safari/537.36',\n",
    "            'Accept-Language': 'en-US, en;q=0.5'})\n",
    "\n",
    "# user define function\n",
    "# Scrape the data\n",
    "def getdata(url):\n",
    "    r = requests.get(url, headers=HEADERS)\n",
    "    return r.text\n",
    "\n",
    "\n",
    "def html_code(url):\n",
    "\n",
    "    # pass the url\n",
    "    # into getdata function\n",
    "    htmldata = getdata(url)\n",
    "    soup = BeautifulSoup(htmldata, 'html.parser')\n",
    "\n",
    "    #display html code\n",
    "    return (soup)\n",
    "\n",
    "\n",
    "url = \"https://www.amazon.in/dp/B09G9G9C2K/ref=redir_mobile_desktop?_encoding=\\\n",
    "    UTF8&aaxitk=c5ff115c1ba1d9f7edec86bc8c6a4f99&hsa_cr_id=9638012290402&pd_rd_plhdr=t&pd_rd_r=\\\n",
    "    afaec463-9f0f-4512-b2d3-240fa990ad1d&pd_rd_w=7msXL&pd_rd_wg=2F2hi&ref_=sbx_be_s_sparkle_mcd_asin_0_img&th=1\"\n",
    "\n",
    "soup = html_code(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66554cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Customer Names\n",
    "\n",
    "def cus_data(soup):\n",
    "# find the Html tag\n",
    "# with find()\n",
    "# and convert into string\n",
    "    data_str = \"\"\n",
    "    cus_list = []\n",
    "\n",
    "    for item in soup.find_all(\"span\", class_=\"a-profile-name\"):\n",
    "        data_str = data_str + item.get_text()\n",
    "        cus_list.append(data_str)\n",
    "        data_str = \"\"\n",
    "    return cus_list\n",
    "\n",
    "#Listing the Customers\n",
    "cus_res = cus_data(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe5234bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Reviews\n",
    "def cus_rev(soup):\n",
    "    # find the Html tag\n",
    "    # with find()\n",
    "    # and convert into string\n",
    "    data_str = \"\"\n",
    "\n",
    "    #To Get Review from this Tag\n",
    "    for item in soup.find_all(\"div\",class_=\"a-expander-content reviewText review-text-content a-expander-partial-collapse-content\"):\n",
    "        data_str = data_str + item.get_text()\n",
    "\n",
    "    result = data_str.split(\"\\n\")\n",
    "    return (result)\n",
    "\n",
    "rev_data = cus_rev(soup)\n",
    "rev_result = []\n",
    "for i in rev_data:\n",
    "    if i is \"\":\n",
    "        pass\n",
    "    else:\n",
    "        rev_result.append(i) #appending the List of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3240d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Save the Review in CSV\n",
    "import pandas as pd\n",
    "\n",
    "# initialise data of lists.\n",
    "data = {'Name': cus_res,\n",
    "        'review': rev_result}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the output.\n",
    "df.to_csv('C:/Users/Akaash/Downloads/amazon_review.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8ce11d",
   "metadata": {},
   "source": [
    "Inference: Did Web-Scraping And Saved the Data to the local Directory Now Will Do Emotion mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8707d0",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30f98d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Required Library\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import string \n",
    "import spacy \n",
    "\n",
    "from matplotlib.pyplot import imread\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2e05d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anil</td>\n",
       "      <td>Its really Shocking that there is no charger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jofert</td>\n",
       "      <td>Like iphone 11,12 now 13. All same look and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vempati Harish Chakravarthi</td>\n",
       "      <td>There are a bunch of reviews on the product ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nitin Verma</td>\n",
       "      <td>Same as previous model iPhone 12 with smalle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brajesh Bharti</td>\n",
       "      <td>I would suggest 12 Pro over 13 mini. Just a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ishaan Aditya</td>\n",
       "      <td>I've been using the iPhone 13 mini for more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Joshuaa Anand</td>\n",
       "      <td>Writing from 'iPhone xs max' I dint see a RE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arvind</td>\n",
       "      <td>Appleâs another generation phone with noth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  \\\n",
       "0                         Anil   \n",
       "1                       Jofert   \n",
       "2  Vempati Harish Chakravarthi   \n",
       "3                  Nitin Verma   \n",
       "4               Brajesh Bharti   \n",
       "5                Ishaan Aditya   \n",
       "6               Joshuaa Anand    \n",
       "7                       Arvind   \n",
       "\n",
       "                                              review  \n",
       "0    Its really Shocking that there is no charger...  \n",
       "1    Like iphone 11,12 now 13. All same look and ...  \n",
       "2    There are a bunch of reviews on the product ...  \n",
       "3    Same as previous model iPhone 12 with smalle...  \n",
       "4    I would suggest 12 Pro over 13 mini. Just a ...  \n",
       "5    I've been using the iPhone 13 mini for more ...  \n",
       "6    Writing from 'iPhone xs max' I dint see a RE...  \n",
       "7    Appleâs another generation phone with noth...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading The Dataset\n",
    "reviews=pd.read_csv(\"C:/Users/Akaash/Downloads/amazon_review.csv\", encoding = 'Latin-1')\n",
    "reviews.drop(['Unnamed: 0'],inplace = True, axis = 1)\n",
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db91e4eb",
   "metadata": {},
   "source": [
    "#### Pre - Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2c1e25d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Its really Shocking that there is no charger which is totally a scam with the customers by Apple they think Indians are Fool and some Indians  are really doing foolish by purchasing this Iphone without charger...don't buy Iphone until they  provide charger total boycott this Iphone...\",\n",
       " 'Like iphone 11,12 now 13. All same look and minor differences. Why Apple fellows release phone with no new features',\n",
       " 'There are a bunch of reviews on the product already. Just sharing my 1st day experience so far, I loved it. This is a major upgrade for me, I jumped from iPhone 7 to 13mini after 4 years. Always wanted to smaller iPhone and looks like so far 13mini is by far the best predecessor of iPhone 7( for me interns of size vs performance ratio). Fantastic Camera, better battery life, and incredibly light phone. All the faults from iPhone 12mini are addressed in this phone. This will be a model which I can hold for at-least next three years in my opinion.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove both the leading and the trailing characters\n",
    "reviews = [review.strip() for review in reviews.review] \n",
    "# removes empty strings, because they are considered in Python as False\n",
    "reviews = [review for review in reviews if review] \n",
    "reviews[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90dc95cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining the list into one string/text\n",
    "review_text = ' '.join(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7432e81",
   "metadata": {},
   "source": [
    "#### POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a25a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Part Of Speech Tagging\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#Taking a Part of the Corpus and Tagging is POS\n",
    "one_block = review_text\n",
    "doc_block = nlp(one_block)\n",
    "\n",
    "#Tokenization with POS Tagged\n",
    "for token in doc_block[0:20]:\n",
    "    print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e1f236",
   "metadata": {},
   "source": [
    "Inference: Parts of Speech for the first 20 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf24433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering for nouns and verbs only\n",
    "nouns_verbs = [token.text for token in doc_block if token.pos_ in ('NOUN', 'VERB')]\n",
    "print(nouns_verbs[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbac9d3",
   "metadata": {},
   "source": [
    "Inference: Noun & Verbs from first 50 Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d48bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting tokens again\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "X = cv.fit_transform(nouns_verbs)\n",
    "sum_words = X.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "wf_df = pd.DataFrame(words_freq)\n",
    "wf_df.columns = ['word', 'count']\n",
    "\n",
    "#Top 10\n",
    "wf_df[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba1e15",
   "metadata": {},
   "source": [
    "Inference: Top 10 Words/Token of Noun & Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb0792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Visualizing results\n",
    "#Barchart for top 10 nouns + verbs\n",
    "wf_df[0:10].plot.bar(x='word', figsize=(12,8), title='Top verbs and nouns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039268f4",
   "metadata": {},
   "source": [
    "Inference: We Can See the Count of Each Words in the Bar Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf32cc2",
   "metadata": {},
   "source": [
    "### Emotion Mining / Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1728ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking Each Tweets as one Token(Sentence)\n",
    "from nltk import tokenize\n",
    "sentences = tokenize.sent_tokenize(\" \".join(reviews))\n",
    "sentences[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852ac84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Dataframe of Sentences\n",
    "sent_df = pd.DataFrame(sentences, columns=['sentence'])\n",
    "sent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca1cfa8",
   "metadata": {},
   "source": [
    "Inference: We Have Total 76 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817543da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment analysis - Loading Afinn Lexicon\n",
    "afinn = pd.read_csv('C:/Users/Akaash/Downloads/Afinn.csv', sep=',', encoding='latin-1')\n",
    "afinn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75505677",
   "metadata": {},
   "source": [
    "Inference: Loaded the afinn Lexicon for emotion mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a92e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the affinity_scores from lexicon into Dictionary\n",
    "affinity_scores = afinn.set_index('word')['value'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1397f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom function :score each word in a sentence in lemmatised form, \n",
    "#but calculate the score for the whole original sentence.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "sentiment_lexicon = affinity_scores\n",
    "\n",
    "def calculate_sentiment(text: str = None):\n",
    "    sent_score = 0\n",
    "    if text:\n",
    "        sentence = nlp(text)\n",
    "        for word in sentence:\n",
    "            sent_score += sentiment_lexicon.get(word.lemma_, 0)\n",
    "    return sent_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5237d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the function \n",
    "calculate_sentiment(text = 'worst')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a283399d",
   "metadata": {},
   "source": [
    "Inference: User Defined Function Words Properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a27040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying to the Whole DataFrame\n",
    "sent_df['sentiment_value'] = sent_df['sentence'].apply(calculate_sentiment)\n",
    "\n",
    "# how many words are in the sentence? (Adding Wordcount column)\n",
    "sent_df['word_count'] = sent_df['sentence'].str.split().apply(len)\n",
    "sent_df['word_count'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc0182a",
   "metadata": {},
   "source": [
    "#### Descriptive Stats on the affinity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment score of the whole review\n",
    "sent_df['sentiment_value'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27140175",
   "metadata": {},
   "source": [
    "Inferences : Max Score is 6, Min Score is -7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9726964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment score of the review - Negative Score Filtering\n",
    "sent_df[sent_df['sentiment_value']<0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65f72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment score of the review - Positive Score Filtering\n",
    "sent_df[sent_df['sentiment_value']>0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c2a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment score of the review - Lowest Score Filtering\n",
    "sent_df[sent_df['sentiment_value']<-6].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment score of the review - Highest ScoreFiltering\n",
    "sent_df[sent_df['sentiment_value']>5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b6a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding A index Column\n",
    "sent_df['index']=range(0,len(sent_df))\n",
    "sent_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7253fbe",
   "metadata": {},
   "source": [
    "#### Visualization of Sentiment / Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.distplot(sent_df['sentiment_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636c4ac1",
   "metadata": {},
   "source": [
    "Inference: It is Left Skewed, thus Making the reviews more of Negative Kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Line Chart\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.lineplot(y='sentiment_value',x='index',data=sent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10677ba0",
   "metadata": {},
   "source": [
    "Inference: Here We Can say the Tweets mostly Comes under the range of -2 to 2 which can be Called as a Neutral, with Some Positive and Negative spikes in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e112473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatterplot\n",
    "sent_df.plot.scatter(x='word_count', y='sentiment_value', figsize=(8,8), \n",
    "                     title='Sentence sentiment value to sentence word count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9464d9e",
   "metadata": {},
   "source": [
    "Inference: From this Plot, it can be seen it does not really matter word count to have good sentiment_value or bad sentiment value as it can be seen, No Relationship betwwen Sentiment_value & word_count, And we can say this Corpus has a Neutral Polarity here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b2269c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
